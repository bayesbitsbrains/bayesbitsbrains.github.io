# Resources <a id="resources"></a>

Here are some great resources for further exploring KL divergence and related topics. 

## üìù Blog posts <a id="introductory-resources"></a>
- A [series](https://www.lesswrong.com/w/bayes-rule) of great explanations and applications of Bayes' rule by alexei and E. Yudkowsky
- A [series](https://blog.alexalemi.com/kl.html) of [amazing](https://blog.alexalemi.com/kl-is-all-you-need.html) blog [posts](https://blog.alexalemi.com/diffusion.html) at _Alex Alemi's blog_ about intuition for KL divergence and its applications. 
- [Amazing post with different intuitions behind KL divergence](https://www.lesswrong.com/posts/no5jDTut5Byjqb4j5/six-and-a-half-intuitions-for-kl-divergence): a LessWrong post by CallumMcDougall. 

Other blog posts
- [Intuition behind KL Divergence](https://johfischer.com/2021/12/31/intuitive-explanation-of-the-kullback-leibler-divergence/) by Johannes Schusterbauer. 
- [Intuition behind KL divergence](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) by Will Kurt. 
- [Maximum Entropy and Bayes' rule](https://risingentropy.com/maximum-entropy-and-bayes/) by Rising Entropy blog
- [Minimum relative entropy and maximum entropy principle](https://caseychu.io/posts/maximum-entropy-kl-divergence-and-bayesian-inference/#:~:text=,one%20with%20the%20maximum%20entropy)
- [Lecture notes on MLE, minimum relative entropy, maximum entropy](https://sites.stat.washington.edu/mmp/courses/stat538/winter12/Handouts/l8-maxent.pdf#:~:text=q0,x)

## üìö Books <a id="intermediate-resources"></a>
RTFM
- [Probability Theory: The Logic of Science](https://bayes.wustl.edu/etj/prob/book.pdf) by E. Jaynes <Footnote>Jaynes is the father of maximum entropy principle and other profound ideas. His book is at times philosophical, and usually very enlightening. Also, it is unfinished and contains errors.</Footnote>

Other books
- [Elements of Information Theory](https://www.wiley.com/en-us/Elements+of+Information+Theory%2C+2nd+Edition-p-9780471241959) by Thomas Cover & Joy Thomas
- [Entropic Physics](https://drive.google.com/file/d/1faiZCbg_HnmKayI7hBFWfhNSuZZU451Y/view) by Ariel Caticha 
- [Machine Learning: A Probabilistic Perspective](https://probml.github.io/pml-book/book0.html) by Kevin P. Murphy
- [Information Theory, Inference, and Learning Algorithms](https://www.inference.org.uk/itprnn/book.html) by David MacKay


## üöÄ What's next? <a id="next-steps"></a>

Anything we should add to the list? <a href="about#feedback">Let us know!</a> 